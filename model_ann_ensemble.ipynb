{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, BatchNormalization, Activation, GlobalAveragePooling1D, Dropout, Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 123\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = r\"C:\\Users\\tmhnguyen\\Documents\\lalamove\\lalamove\\data\\Clean_extracted_240115_uncal\\train\"\n",
    "labels = [5, 6, 7]\n",
    "synthetic_percent = {5: 0.8, 6: 0.1, 7: 0.5}\n",
    "with open(basedir + '/../data_split_params.json', 'r') as file:\n",
    "    features = json.load(file)['FEATURES']\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ori = pd.read_csv(basedir + f'/{label}/train_label_{label}.csv')\n",
    "X_ori = []\n",
    "step = 30_000\n",
    "for i in range(np.ceil(len(y_ori)/30_000).astype(int)):\n",
    "    temp = pd.read_csv(basedir + f'/{label}/extract_features_{label}_{i}.csv', index_col=0)\n",
    "    X_ori.append(temp)\n",
    "X_ori = pd.concat(X_ori)\n",
    "assert len(X_ori) == len(y_ori), f\"Length mismatch {len(X_ori)}, {len(y_ori)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(xtrain, input_shape=500):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    scaler = Normalization()\n",
    "    scaler.adapt(xtrain)\n",
    "    scaled_inputs = scaler(inputs)\n",
    "    x = Dense(500, activation='relu')(scaled_inputs)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test date is  20231228 (389287, 500) (389287, 6) (368768, 500) (368768, 6)\n"
     ]
    }
   ],
   "source": [
    "dates = y_ori.date.unique()\n",
    "test_date = dates[-3]\n",
    "test_idx = y_ori[(y_ori.date == test_date) & (y_ori.type == 0)].index\n",
    "\n",
    "X_test = X_ori.iloc[test_idx]\n",
    "y_test = y_ori.iloc[test_idx].label\n",
    "\n",
    "y = y_ori[y_ori.date != test_date]\n",
    "X = X_ori.iloc[y.index]\n",
    "\n",
    "print('test date is ', test_date, X_ori.shape, y_ori.shape, X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th model in the ensemble 20231107\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\indexing.py:1676\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4079\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4081\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4086\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4087\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4088\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4089\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4066\u001b[0m     )\n\u001b[1;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4075\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\internals\\managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    873\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m train_idx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train_idx, train_idx_add])\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     13\u001b[0m X\u001b[38;5;241m.\u001b[39miloc[val_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx_add\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     16\u001b[0m X_train_en, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_idx]\u001b[38;5;241m.\u001b[39mto_numpy(), X\u001b[38;5;241m.\u001b[39miloc[val_idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     17\u001b[0m y_train_en, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx]\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mto_numpy(), y\u001b[38;5;241m.\u001b[39miloc[val_idx]\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\indexing.py:1705\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1709\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32mc:\\Users\\tmhnguyen\\.conda\\envs\\lalamove\\lib\\site-packages\\pandas\\core\\indexing.py:1679\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "n_models = len(dates) - 1\n",
    "rand_states = np.random.randint(1, 10000, size=n_models)\n",
    "for i, val_date in enumerate([d for d in dates if d != test_date]):\n",
    "    print(f'{i+1}th model in the ensemble', dates[i])\n",
    "    tf.keras.backend.clear_session() # release resource associated with previous model\n",
    "    \n",
    "    val_idx = y[(y.date == val_date) & (y.type == 0)].index\n",
    "    train_idx = y[(y.date != val_date) & (y.type == 0)]\n",
    "    train_idx_add = y[(y.date != val_date) & (y.type == 1)].sample(frac=synthetic_percent[label])\n",
    "    train_idx = pd.concat([train_idx, train_idx_add]).index\n",
    "\n",
    "    X.iloc[val_idx].to_numpy()\n",
    "    X.iloc[train_idx_add.index].to_numpy()\n",
    "\n",
    "    X_train_en, X_val = X.iloc[train_idx].to_numpy(), X.iloc[val_idx].to_numpy()\n",
    "    y_train_en, y_val = y.iloc[train_idx].label.to_numpy(), y.iloc[val_idx].label.to_numpy()\n",
    "    \n",
    "    print(X_train_en.shape, X_val.shape)\n",
    "\n",
    "    model = create_model(X_train_en, input_shape=X_train_en.shape[1])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=2e-5),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[BinaryAccuracy(name='acc'),\n",
    "                        Precision(name='precision'),\n",
    "                        Recall(name='recall')])\n",
    "\n",
    "    history = model.fit(X_train_en, y_train_en, batch_size=256, epochs=5, validation_data=(X_val, y_val),\n",
    "                        callbacks=[EarlyStopping(patience=20,\n",
    "                                        min_delta=0.0005,\n",
    "                                        restore_best_weights=True)],\n",
    "                        verbose=False)\n",
    "    loss_v, acc_v, precision_v, recall_v = model.evaluate(X_val, y_val)\n",
    "    # print(f' on validation set - loss: {loss_v:.4f}, accuracy: {acc_v:.4f}, precision: {precision_v:.4f}, recal: {recall_v:.4f}')\n",
    "    model.save(basedir + f'/../model_ann_ensemble/{label}/model_{label}_no_{i}.hdf5')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, xtest):\n",
    "    ensemble_predictions = np.mean([model.predict(xtest) for model in models], axis=0)\n",
    "    return ensemble_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, col='pred'):\n",
    "    true, pred = row.true, row[col]\n",
    "    if true == pred and true == 0:\n",
    "        return 'True Negative'\n",
    "    elif true == pred and true == 1:\n",
    "        return 'True Positive'\n",
    "    elif true != pred and true == 0:\n",
    "        return 'False Positive'\n",
    "    else:\n",
    "        return 'False Negative'\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(models), ncols=2, figsize=(10, 25))\n",
    "for k, model in enumerate(models):    \n",
    "    pred = model.predict(X_test) >= 0.5\n",
    "    df = pd.DataFrame(np.hstack((y_test.to_numpy().reshape(-1, 1), pred)), columns=['true', 'pred'])\n",
    "    df.pred = df.pred.astype(int)        \n",
    "    df['type'] = df.apply(lambda x: classify(x), axis=1)\n",
    "    types = df.type.value_counts().sort_index()[::-1]\n",
    "\n",
    "    w = 5 # window in seconds\n",
    "    pred_avg = np.convolve(pred.flatten(), np.ones(w), mode='same') / w >= 0.5\n",
    "    df['pred_avg'] = pred_avg\n",
    "    df.pred_avg = df.pred_avg.astype(int)        \n",
    "    df['type_avg'] = df.apply(lambda x: classify(x, col='pred_avg'), axis=1)\n",
    "    types_avg = df.type_avg.value_counts().sort_index()[::-1]\n",
    "\n",
    "    colors = ['skyblue', 'blue', 'green', 'red']\n",
    "    types_ = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "    i = 0.5\n",
    "    for j, t in enumerate(types_):\n",
    "        try:\n",
    "            axes[k, 0].scatter(df[df.type==t].index, [i]*types[t], label=t, c=colors[j])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        i += 0.1\n",
    "\n",
    "    axes[k, 0].set_ylim(0, 2)\n",
    "    axes[k, 0].get_yaxis().set_visible(False)\n",
    "    axes[k, 0].set_title(f'Label {label} - test_date {dates[k]}')\n",
    "\n",
    "    i = 0.5\n",
    "    for j, t in enumerate(types_):\n",
    "        try:\n",
    "            axes[k, 1].scatter(df[df.type_avg==t].index, [i]*types_avg[t], label=t, c=colors[j])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        i += 0.1\n",
    "\n",
    "    axes[k, 1].set_ylim(0, 2)\n",
    "    axes[k, 1].get_yaxis().set_visible(False)\n",
    "    axes[k, 1].set_title(f'Label {label} - test_date {dates[k]}')  \n",
    "\n",
    "axes[0, 0].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble_predict(models, X_test) >= 0.5\n",
    "print(pred.shape, y_test.shape)\n",
    "\n",
    "df = pd.DataFrame(np.hstack((y_test.to_numpy().reshape(-1, 1), pred)), columns=['true', 'pred'])\n",
    "df.pred = df.pred.astype(int)\n",
    "\n",
    "def classify(row):\n",
    "    true, pred = row.true, row.pred\n",
    "    if true == pred and true == 0:\n",
    "        return 'True Negative'\n",
    "    elif true == pred and true == 1:\n",
    "        return 'True Positive'\n",
    "    elif true != pred and true == 0:\n",
    "        return 'False Positive'\n",
    "    else:\n",
    "        return 'False Negative'\n",
    "    \n",
    "df['type'] = df.apply(lambda x: classify(x), axis=1)\n",
    "types = df.type.value_counts().sort_index()[::-1]\n",
    "print(types)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 2.5))\n",
    "i = 0\n",
    "colors = ['skyblue', 'blue', 'green', 'red']\n",
    "types_ = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for j, t in enumerate(types_):\n",
    "    try:\n",
    "        ax.scatter(df[df.type==t].index, [i]*types[t], label=t, c=colors[j])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    i += 0.1\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 2)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_title(f'{label} NO average smoothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble_predict(models, X_test).flatten() \n",
    "print(pred.shape, y_test.shape)\n",
    "w = 5 # window in seconds\n",
    "pred = np.convolve(pred, np.ones(w), mode='same') / w >= 0.5\n",
    "\n",
    "print(pred.shape, y_test.shape)\n",
    "df = pd.DataFrame(np.stack((y_test, pred)).T, columns=['true', 'pred'])\n",
    "df.pred = df.pred.astype(int)\n",
    "\n",
    "def classify(row):\n",
    "    true, pred = row.true, row.pred\n",
    "    if true == pred and true == 0:\n",
    "        return 'True Negative'\n",
    "    elif true == pred and true == 1:\n",
    "        return 'True Positive'\n",
    "    elif true != pred and true == 0:\n",
    "        return 'False Positive'\n",
    "    else:\n",
    "        return 'False Negative'\n",
    "    \n",
    "df['type'] = df.apply(lambda x: classify(x), axis=1)\n",
    "types = df.type.value_counts().sort_index()[::-1]\n",
    "print(types)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 2.5))\n",
    "i = 0\n",
    "colors = ['skyblue', 'blue', 'green', 'red']\n",
    "types_ = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for j, t in enumerate(types_):\n",
    "    try:\n",
    "        ax.scatter(df[df.type==t].index, [i]*types[t], label=t, c=colors[j])\n",
    "    except KeyError:\n",
    "        print(f'There is no {t}')\n",
    "    i += 0.1\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 2)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_title(f'{label} with average smoothing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsfresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
